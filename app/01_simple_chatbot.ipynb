{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¤– Simple Chatbot - AI Education Project\n",
        " \n",
        "**Description:** Basic Q&A chatbot to learn how AI conversations work\n",
        " \n",
        "**Curriculum Phase:** C (Kelas 5-6 SD)\n",
        " \n",
        "**Difficulty:** Beginner\n",
        " \n",
        "This notebook will teach you how to create a simple chatbot that can answer questions and have conversations!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š STEP 1: Install Dependencies\n",
        "First, we need to install the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q requests gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š STEP 2: Setup\n",
        "\n",
        "Import the libraries and set up the backend URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "# Obfuscated credentials\n",
        "_BACKEND = base64.b64decode(\"aHR0cHM6Ly9sbG0tcHJveHktMzY0ODg2Mjk4ODY2LnVzLWNlbnRyYWwxLnJ1bi5hcHA=\").decode()\n",
        "_KEY = base64.b64decode(\"a2thLXNlY3JldC0yMDI1LXg3Sm05UHEyV241UnQ4THYzS3M2SGc0WXo=\").decode()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š STEP 3: Core Function\n",
        "This function sends your message to the AI and gets a response back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to send message to AI and get response\n",
        "def chat_with_ai(user_message, history):\n",
        "    \"\"\"Send message to AI and get response with conversation history\"\"\"\n",
        "    try:\n",
        "        # Convert Gradio history format to API format\n",
        "        # Gradio history: [[user_msg, bot_msg], [user_msg, bot_msg], ...]\n",
        "        # API history: [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}, ...]\n",
        "        api_history = []\n",
        "        for user_msg, bot_msg in history:\n",
        "            api_history.append({\"role\": \"user\", \"content\": user_msg})\n",
        "            api_history.append({\"role\": \"assistant\", \"content\": bot_msg})\n",
        "        \n",
        "        response = requests.post(\n",
        "            f\"{_BACKEND}/chat/elementary\",\n",
        "            headers={\"X-API-Key\": _KEY},\n",
        "            json={\n",
        "                \"prompt\": user_message,\n",
        "                \"history\": api_history if api_history else None\n",
        "            },\n",
        "            timeout=30\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        return response.json()[\"response\"]\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š STEP 4: Create Interface\n",
        "\n",
        "Set up the chat interface with Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        }
      ],
      "source": [
        "interface = gr.ChatInterface(\n",
        "    fn=chat_with_ai,\n",
        "    title=\"ðŸ¤– Simple Chatbot\",\n",
        "    description=\"Ask me anything! I'm here to help you learn.\",\n",
        "    examples=[\n",
        "        \"Apa itu kecerdasan buatan?\",\n",
        "        \"Ceritakan tentang dinosaurus!\",\n",
        "        \"Bagaimana cara membuat robot?\"\n",
        "    ],\n",
        "    theme=\"soft\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š STEP 5: Launch!\n",
        "\n",
        "Run this cell to start chatting with your AI!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://87f1556cff378f0032.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://87f1556cff378f0032.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interface.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ LEARNING SECTION\n",
        "\n",
        "#### What's happening here?\n",
        "\n",
        "1. **The AI Model**: We're using a language model (GPT-4o-mini) that has been trained on lots of text to understand and generate human-like responses.\n",
        "\n",
        "2. **How it works**:\n",
        "   - You type a message\n",
        "   - Your message is sent to our backend server\n",
        "   - The server sends it to the AI model\n",
        "   - The AI thinks and generates a response\n",
        "   - The response comes back to you!\n",
        "\n",
        "3. **What are prompts?**: A prompt is the instruction or question you give to the AI. Good prompts get better responses!\n",
        "\n",
        "#### Try modifying this app:\n",
        "\n",
        "1. Change the examples to your favorite topics\n",
        "2. Modify the title and description\n",
        "3. Try asking the AI to respond in a specific style (like a pirate or a scientist!)\n",
        "\n",
        "#### Questions to think about:\n",
        "\n",
        "- How does the AI know what to say?\n",
        "- Can the AI make mistakes?\n",
        "- What happens if you ask something the AI doesn't know?\n",
        "\n",
        "Have fun exploring!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
